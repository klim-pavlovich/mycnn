{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторная 2. Реализация сверточной нейронной сети для классификации цифр\n",
    "Исходные данные - база MNIST (http://yann.lecun.com/exdb/mnist/). Обучающая выборка - 70%, тестовая - 30%.\n",
    "Количество слоев, размерность свертки и гиперпараметры свертки и пулинга на Ваше усмотрение\n",
    "обучение - обратное распространение ошибки, средняя ошибка - 0,0001\n",
    "реализовать вычисление матрицы неточностей, по которой должны вычисляться показатели accuracy, precision, recall, F-мера, строится ROC-кривая, вычислятся AUC. Предварительно построить t-SNE и оценить причины ошибочной классификации\n",
    "DropOut и batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read magic number: 2051\n",
      "Images: num_images=60000, rows=28, cols=28\n",
      "Loaded 47040000 image pixels.\n",
      "Read magic number: 2049\n",
      "Read magic number: 2051\n",
      "Images: num_images=10000, rows=28, cols=28\n",
      "Loaded 7840000 image pixels.\n",
      "Read magic number: 2049\n",
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_idx_file(file_path):\n",
    "    \"\"\" Читает файл в формате IDX (используемый для хранения изображений и меток MNIST).\n",
    "    Если файла содержит изображения, то он будет интерпретирован как набор изображений, если метки - то как массив меток.\n",
    "\n",
    "    Параметры:\n",
    "        file_path (str): Путь к файлу, который нужно прочитать.\n",
    "\n",
    "    Исключения:\n",
    "        ValueError: Если формат файла не соответствует ожидаемому.\n",
    "\n",
    "    Возвращает:\n",
    "        numpy.ndarray: Массив с изображениями или метками, в зависимости от типа файла.\n",
    "    \"\"\"\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        # Чтение магического числа\n",
    "        magic = np.frombuffer(f.read(4), dtype=np.uint32).byteswap()  # Используем byteswap для правильной обработки порядка байтов\n",
    "        print(f\"Read magic number: {magic[0]}\")\n",
    "\n",
    "        if magic == 2051:  # Это изображение\n",
    "            # Чтение метаданных: количество изображений, строки и столбцы\n",
    "            num_images = np.frombuffer(f.read(4), dtype=np.uint32).byteswap()[0]\n",
    "            rows = np.frombuffer(f.read(4), dtype=np.uint32).byteswap()[0]\n",
    "            cols = np.frombuffer(f.read(4), dtype=np.uint32).byteswap()[0]\n",
    "            print(f\"Images: num_images={num_images}, rows={rows}, cols={cols}\")\n",
    "\n",
    "            # Загружаем все пиксели\n",
    "            images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            print(f\"Loaded {images.size} image pixels.\")\n",
    "\n",
    "            # Проверяем количество пикселей\n",
    "            expected_pixels = num_images * rows * cols\n",
    "            if images.size != expected_pixels:\n",
    "                raise ValueError(f\"Mismatch in number of pixels. Expected {expected_pixels}, but got {images.size}.\")\n",
    "\n",
    "            # Преобразуем в массив изображений\n",
    "            images = images.reshape(num_images, rows, cols)\n",
    "            return images\n",
    "\n",
    "        elif magic == 2049:  # Это метки\n",
    "            num_labels = np.frombuffer(f.read(4), dtype=np.uint32).byteswap()[0]\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            return labels\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown IDX file format: {magic}\")\n",
    "\n",
    "def load_mnist_data():\n",
    "    \"\"\" Загружает данные MNIST для обучения и тестирования,\n",
    "    используя функцию 'read_idx_file' для чтения сжатый файлов данных.\n",
    "\n",
    "    Возвращает:\n",
    "        tuple:\n",
    "            - numpy.ndarray: Массив изображений для обучающей выборки, размерность (num_images, rows, cols).\n",
    "            - numpy.ndarray: Массив меток для обучающей выборки, размерность (num_labels,).\n",
    "            - numpy.ndarray: Массив изображений для тестовой выборки, размерность (num_images, rows, cols).\n",
    "            - numpy.ndarray: Массив меток для тестовой выборки, размерность (num_labels,).\n",
    "    \"\"\"\n",
    "    data_dir = './data'  # Указываем путь папки с данными\n",
    "    # Чтение изображений и меток\n",
    "    train_images = read_idx_file(os.path.join(data_dir, 'train-images-idx3-ubyte.gz'))\n",
    "    train_labels = read_idx_file(os.path.join(data_dir, 'train-labels-idx1-ubyte.gz'))\n",
    "    test_images = read_idx_file(os.path.join(data_dir, 't10k-images-idx3-ubyte.gz'))\n",
    "    test_labels = read_idx_file(os.path.join(data_dir, 't10k-labels-idx1-ubyte.gz'))\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Загрузка данных\n",
    "X_train, Y_train, X_test, Y_text = load_mnist_data()\n",
    "\n",
    "# Проверим размерности данных\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv2d(input, filters, biases, stride=1, padding=0):\n",
    "#     \"\"\"\n",
    "#     Применение 2D-свертки.\n",
    "\n",
    "#     :param input: Входной тензор (batch_size, height, width, channels)\n",
    "#     :param filters: Фильтры (num_filters, filter_height, filter_width, channels)\n",
    "#     :param bias: Смещение  для выхода каждого фильтра после свертки (num_filters)\n",
    "#     :param stride: Шаг свертки\n",
    "#     :param padding: Отступ для входного изображения\n",
    "#     :return: Свертка\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Паддинг\n",
    "#     if padding < 0:\n",
    "#         raise ValueError(\"Паддинг должен быть неотрицательным целым числом.\")\n",
    "\n",
    "#     # Размеры входных тензеров\n",
    "#     batch_size, in_height, in_width, in_channels = input.shape\n",
    "#     num_filters, filter_height, filter_width, _ = filters.shape\n",
    "\n",
    "#     # Применяем паддинг, если он задан\n",
    "#     if padding > 0:\n",
    "#         input = np.pad(input, ((0,), (padding,), (padding,), (0,)), mode='constant', constant_values=0)\n",
    "\n",
    "#     # Вычисляем размерности выходного тензора\n",
    "#     out_height = (in_height - filter_height + 2 * padding) // stride + 1\n",
    "#     out_width = (in_width - filter_width + 2 * padding) // stride + 1\n",
    "\n",
    "#     # Используем \"strides\" для извлечения всех регионов из входного тензора за один шаг\n",
    "#     # Создаем 3D представление для каждого региона в 2D\n",
    "#     input_unf = np.lib.stride_tricks.as_strided(input, \n",
    "#                                                 shape=(batch_size, out_height, out_width, filter_height, filter_width, in_channels), \n",
    "#                                                 strides=(input.strides[0], stride * input.strides[1], stride * input.strides[2], \n",
    "#                                                          input.strides[1], input.strides[2], input.strides[3]))\n",
    "\n",
    "#     # Переводим каждый регион в одномерный вектор\n",
    "#     input_unf = input_unf.reshape(batch_size, out_height, out_width, -1)\n",
    "\n",
    "#     # Применяем свертку с фильтрами\n",
    "#     filters_reshaped = filters.reshape(num_filters, -1)  # Изменяем фильтры в одномерные векторы\n",
    "#     output = np.tensordot(input_unf, filters_reshaped.T, axes=((3,), (1,)))  # Применяем умножение (векторизация)\n",
    "    \n",
    "#     # Добавляем смещения\n",
    "#     output += biases\n",
    "    \n",
    "#     return output\n",
    "\n",
    "\n",
    "#     # # Выходной тензор\n",
    "#     # output = np.zeros((batch_size, out_height, out_width, num_filters))\n",
    "\n",
    "#     # # Применяем фильтры\n",
    "#     # for i in range(num_filters):\n",
    "#     #     filter_ = filters[i] # Получаем текущий фильтр\n",
    "#     #     for j in range(0, in_height - filter_height + 1, stride):\n",
    "#     #         for k in range(0, in_width - filter_width + 1, stride):\n",
    "#     #             region = input[:, j:j+filter_height, k:k+filter_width, :]\n",
    "#     #             output[:, j//stride, k//stride, i] = np.sum(region * filter_, axis=(1, 2, 3))\n",
    "\n",
    "#     # return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\klimm\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\klimm\\AppData\\Local\\Temp\\ipykernel_14600\\1730988995.py\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py\", line 148, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"c:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Преобразование изображения для свертки (28x28 -> 28x28x1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Добавляем ось канала (для одноцветных изображений это будет 1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:148\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32mc:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\klimm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Преобразование изображения для свертки (28x28 -> 28x28x1)\n",
    "def preprocess_image(image):\n",
    "    # Добавляем ось канала (для одноцветных изображений это будет 1)\n",
    "    return image.reshape(1, 28, 28, 1)\n",
    "\n",
    "# Пример простых фильтров (например, для извлечения горизонтальных и вертикальных границ)\n",
    "def initialize_filters():\n",
    "    filters = np.zeros((2, 3, 3, 1))  # 2 фильтра размером 3x3 для 1 канала\n",
    "    filters[0, :, :, 0] = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])  # Фильтр для вертикальных границ\n",
    "    filters[1, :, :, 0] = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])  # Фильтр для горизонтальных границ\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим одно изображение из MNIST для примера\n",
    "image = X_train[0]  # Берем первое изображение из тренировочных данных\n",
    "\n",
    "# Преобразуем изображение в нужную форму\n",
    "image_input = preprocess_image(image)\n",
    "\n",
    "# Инициализируем фильтры\n",
    "filters = initialize_filters()\n",
    "\n",
    "# Инициализируем смещения для каждого фильтра (обычно они небольшие)\n",
    "biases = np.zeros(2)\n",
    "\n",
    "# Применим свертку\n",
    "output = conv2d(image_input, filters, biases, stride=1, padding=0)\n",
    "\n",
    "# Размерность выходного тензора (batch_size, out_height, out_width, num_filters)\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "# Функция для отображения изображения\n",
    "def plot_image(image, title=\"Image\"):\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Визуализируем исходное изображение\n",
    "plot_image(image, title=\"Original Image\")\n",
    "\n",
    "# Визуализируем результаты свертки\n",
    "# Поскольку у нас два фильтра, вывод будет иметь размер (2, 26, 26)\n",
    "# Мы можем отобразить каждое из выходных изображений отдельно\n",
    "\n",
    "for i in range(output.shape[-1]):\n",
    "    plot_image(output[0, :, :, i], title=f\"Filter {i+1} Output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(X, pool_size=2, stride=2):\n",
    "    batch_size, height, width, channels = X.shape\n",
    "    output_height = (height - pool_size) // stride + 1\n",
    "    output_width = (width - pool_size) // stride + 1\n",
    "    \n",
    "    output = np.zeros((batch_size, output_height, output_width, channels))\n",
    "    \n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            X_slice = X[:, i*stride:i*stride+pool_size, j*stride:j*stride+pool_size, :]\n",
    "            output[:, i, j, :] = np.max(X_slice, axis=(1, 2))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "\n",
    "def dense(input, weights, bias):\n",
    "    return np.dot(input, weights) + bias\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "def softmax(X):\n",
    "    exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "    return exp_X / np.sum(exp_X, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9)) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\"\n",
    "    Преобразует метки в формат one-hot encoding.\n",
    "    :param y: Массив меток (batch_size,)\n",
    "    :param num_classes: Количество классов\n",
    "    :return: Массив one-hot encoding (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Инициализация весов для слоев\n",
    "        self.conv1_filters = np.random.randn(3, 3, 1, 3) * 0.01  # 3 фильтра 3x3 для 1 канала\n",
    "        self.conv1_bias = np.zeros(3)\n",
    "        \n",
    "        self.conv2_filters = np.random.randn(3, 3, 3, 3) * 0.01  # 3 фильтра 3x3 для 3 каналов\n",
    "        self.conv2_bias = np.zeros(3)\n",
    "        \n",
    "        # Вычисляем размерность после свертки и пулинга\n",
    "        self.flattened_size = self.calculate_flattened_size(input_shape)\n",
    "        self.fc_weights = np.random.randn(self.flattened_size, 128) * 0.01  # Размерность после свертки и пулинга\n",
    "        self.fc_bias = np.zeros(128)\n",
    "        \n",
    "        self.output_weights = np.random.randn(128, num_classes) * 0.01\n",
    "        self.output_bias = np.zeros(num_classes)\n",
    "\n",
    "    def calculate_flattened_size(self, input_shape):\n",
    "        # Применяем свертку и пулинг для вычисления выходной размерности\n",
    "        # В этом примере мы используем stride=1 и padding='valid'\n",
    "        input = np.zeros((1, *input_shape))  # Подготовим фиктивный тензор для вычислений\n",
    "        conv1_out = conv2d(input, self.conv1_filters)\n",
    "        pool1_out = max_pooling(conv1_out)\n",
    "        conv2_out = conv2d(pool1_out, self.conv2_filters)\n",
    "        pool2_out = max_pooling(conv2_out)\n",
    "        return pool2_out.size  # После пулинга мы знаем, какой размер будет у флаттенед тензора\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        # Свертка первого слоя + активация\n",
    "        self.conv1_out = conv2d(X, self.conv1_filters)\n",
    "        self.conv1_out = relu(self.conv1_out)\n",
    "        \n",
    "        # Слой пулинга\n",
    "        self.pool1_out = max_pooling(self.conv1_out)\n",
    "        \n",
    "        # Свертка второго слоя + активация\n",
    "        self.conv2_out = conv2d(self.pool1_out, self.conv2_filters)\n",
    "        self.conv2_out = relu(self.conv2_out)\n",
    "        \n",
    "        # Слой пулинга\n",
    "        self.pool2_out = max_pooling(self.conv2_out)\n",
    "        \n",
    "        # Флэттенинг (преобразуем вектор в плоскую форму)\n",
    "        self.flattened = flatten(self.pool2_out)\n",
    "        \n",
    "        # Проверяем размерность после флаттенинга\n",
    "        print(f\"Flattened shape: {self.flattened.shape}\")\n",
    "        \n",
    "        # Полносвязный слой\n",
    "        self.fc_out = dense(self.flattened, self.fc_weights, self.fc_bias)\n",
    "        self.fc_out = relu(self.fc_out)\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.output = dense(self.fc_out, self.output_weights, self.output_bias)\n",
    "        self.output = softmax(self.output)\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        d_output = self.output - y\n",
    "        d_output /= m\n",
    "        \n",
    "        d_output_weights = np.dot(self.fc_out.T, d_output)\n",
    "        d_output_bias = np.sum(d_output, axis=0)\n",
    "        \n",
    "        d_fc_out = np.dot(d_output, self.output_weights.T)\n",
    "        d_fc_out[self.fc_out <= 0] = 0\n",
    "        \n",
    "        d_fc_weights = np.dot(self.flattened.T, d_fc_out)\n",
    "        d_fc_bias = np.sum(d_fc_out, axis=0)\n",
    "        \n",
    "        d_pool2_out = np.dot(d_fc_out, self.fc_weights.T)\n",
    "        \n",
    "        d_conv2_out = d_pool2_out.reshape(self.conv2_out.shape)\n",
    "        d_conv2_out[self.conv2_out <= 0] = 0\n",
    "        \n",
    "        d_conv2_filters = np.dot(d_conv2_out, self.pool1_out.T)\n",
    "        d_conv2_bias = np.sum(d_conv2_out, axis=(0, 1, 2))\n",
    "        \n",
    "        d_pool1_out = np.dot(d_conv2_out, self.conv2_filters.T)\n",
    "        \n",
    "        d_conv1_out = d_pool1_out.reshape(self.conv1_out.shape)\n",
    "        d_conv1_out[self.conv1_out <= 0] = 0\n",
    "        \n",
    "        d_conv1_filters = np.dot(d_conv1_out, X.T)\n",
    "        d_conv1_bias = np.sum(d_conv1_out, axis=(0, 1, 2))\n",
    "        \n",
    "        # Обновляем веса\n",
    "        self.conv1_filters -= learning_rate * d_conv1_filters\n",
    "        self.conv1_bias -= learning_rate * d_conv1_bias\n",
    "        self.conv2_filters -= learning_rate * d_conv2_filters\n",
    "        self.conv2_bias -= learning_rate * d_conv2_bias\n",
    "        self.fc_weights -= learning_rate * d_fc_weights\n",
    "        self.fc_bias -= learning_rate * d_fc_bias\n",
    "        self.output_weights -= learning_rate * d_output_weights\n",
    "        self.output_bias -= learning_rate * d_output_bias\n",
    "\n",
    "    def train(self, X_train, y_train, learning_rate=0.001, epochs=10, batch_size=32):\n",
    "        # Убедимся, что X_train имеет правильную форму\n",
    "        if X_train.shape[-1] != 1:\n",
    "            X_train = np.expand_dims(X_train, axis=-1)  # Добавляем канал\n",
    "\n",
    "        num_samples = X_train.shape[0]\n",
    "        \n",
    "        # Преобразуем метки в формат one-hot\n",
    "        y_train = to_categorical(y_train, self.num_classes)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            num_batches = num_samples // batch_size\n",
    "            for batch in range(num_batches):\n",
    "                start_idx = batch * batch_size\n",
    "                end_idx = (batch + 1) * batch_size\n",
    "                X_batch = X_train[start_idx:end_idx]\n",
    "                y_batch = y_train[start_idx:end_idx]\n",
    "                \n",
    "                predictions = self.forward_pass(X_batch)\n",
    "                \n",
    "                loss = cross_entropy_loss(y_batch, predictions)\n",
    "                total_loss += loss\n",
    "                \n",
    "                self.backward_pass(X_batch, y_batch, learning_rate)\n",
    "            \n",
    "            avg_loss = total_loss / num_batches\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\"\n",
    "    Преобразует метки в формат one-hot encoding.\n",
    "    :param y: Массив меток (batch_size,)\n",
    "    :param num_classes: Количество классов\n",
    "    :return: Массив one-hot encoding (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    # Используем small epsilon, чтобы избежать логарифма нуля\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9)) / m\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # Для стабильности чисел\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "def max_pooling(x, pool_size=2, stride=2):\n",
    "    batch_size, in_height, in_width, in_channels = x.shape\n",
    "    out_height = (in_height - pool_size) // stride + 1\n",
    "    out_width = (in_width - pool_size) // stride + 1\n",
    "    out = np.zeros((batch_size, out_height, out_width, in_channels))\n",
    "    for i in range(0, in_height - pool_size + 1, stride):\n",
    "        for j in range(0, in_width - pool_size + 1, stride):\n",
    "            region = x[:, i:i+pool_size, j:j+pool_size, :]\n",
    "            out[:, i//stride, j//stride, :] = np.max(region, axis=(1, 2))\n",
    "    return out\n",
    "\n",
    "def conv2d(input, filters, stride=1, padding='valid'):\n",
    "    batch_size, in_height, in_width, in_channels = input.shape\n",
    "    num_filters, filter_height, filter_width, _ = filters.shape\n",
    "    \n",
    "    # Паддинг\n",
    "    if padding == 'same':\n",
    "        pad_height = (in_height - 1) % stride\n",
    "        pad_width = (in_width - 1) % stride\n",
    "        input = np.pad(input, ((0, 0), (pad_height//2, pad_height//2), (pad_width//2, pad_width//2), (0, 0)), mode='constant')\n",
    "    \n",
    "    out_height = (in_height - filter_height) // stride + 1\n",
    "    out_width = (in_width - filter_width) // stride + 1\n",
    "    \n",
    "    # Выходной тензор\n",
    "    output = np.zeros((batch_size, out_height, out_width, num_filters))\n",
    "    \n",
    "    # Применяем фильтры\n",
    "    for i in range(num_filters):\n",
    "        filter_ = filters[i]\n",
    "        for j in range(0, in_height - filter_height + 1, stride):\n",
    "            for k in range(0, in_width - filter_width + 1, stride):\n",
    "                region = input[:, j:j+filter_height, k:k+filter_width, :]\n",
    "                output[:, j//stride, k//stride, i] = np.sum(region * filter_, axis=(1, 2, 3))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def flatten(x):\n",
    "    return x.reshape(x.shape[0], -1)\n",
    "\n",
    "def dense(input, weights, bias):\n",
    "    return np.dot(input, weights) + bias\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Инициализация весов для слоев\n",
    "        self.conv1_filters = np.random.randn(3, 3, 1, 3) * 0.01  # 3 фильтра 3x3 для 1 канала\n",
    "        self.conv1_bias = np.zeros(3)\n",
    "        \n",
    "        self.conv2_filters = np.random.randn(3, 3, 3, 3) * 0.01  # 3 фильтра 3x3 для 3 каналов\n",
    "        self.conv2_bias = np.zeros(3)\n",
    "        \n",
    "        # Рассчитываем размерность после свертки и пулинга\n",
    "        self.flattened_size = self.calculate_flattened_size(input_shape)\n",
    "        self.fc_weights = np.random.randn(self.flattened_size, 128) * 0.01  # Размерность после свертки и пулинга\n",
    "        self.fc_bias = np.zeros(128)\n",
    "        \n",
    "        self.output_weights = np.random.randn(128, num_classes) * 0.01\n",
    "        self.output_bias = np.zeros(num_classes)\n",
    "\n",
    "    def calculate_flattened_size(self, input_shape):\n",
    "        # Применяем свертку и пулинг для вычисления выходной размерности\n",
    "        input = np.zeros((1, *input_shape))  # Подготовим фиктивный тензор для вычислений\n",
    "        conv1_out = conv2d(input, self.conv1_filters)\n",
    "        pool1_out = max_pooling(conv1_out)\n",
    "        conv2_out = conv2d(pool1_out, self.conv2_filters)\n",
    "        pool2_out = max_pooling(conv2_out)\n",
    "        return pool2_out.size  # После пулинга мы знаем, какой размер будет у флаттенед тензора\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        # Добавляем канал для входных данных\n",
    "        if X.shape[-1] != 1:\n",
    "            X = np.expand_dims(X, axis=-1)\n",
    "        \n",
    "        # Свертка первого слоя + активация\n",
    "        self.conv1_out = conv2d(X, self.conv1_filters)\n",
    "        self.conv1_out = relu(self.conv1_out)\n",
    "        \n",
    "        # Слой пулинга\n",
    "        self.pool1_out = max_pooling(self.conv1_out)\n",
    "        \n",
    "        # Свертка второго слоя + активация\n",
    "        self.conv2_out = conv2d(self.pool1_out, self.conv2_filters)\n",
    "        self.conv2_out = relu(self.conv2_out)\n",
    "        \n",
    "        # Слой пулинга\n",
    "        self.pool2_out = max_pooling(self.conv2_out)\n",
    "        \n",
    "        # Флэттенинг (преобразуем вектор в плоскую форму)\n",
    "        self.flattened = flatten(self.pool2_out)\n",
    "        \n",
    "        # Полносвязный слой\n",
    "        self.fc_out = dense(self.flattened, self.fc_weights, self.fc_bias)\n",
    "        self.fc_out = relu(self.fc_out)\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.output = dense(self.fc_out, self.output_weights, self.output_bias)\n",
    "        self.output = softmax(self.output)\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        d_output = self.output - y\n",
    "        d_output /= m\n",
    "        \n",
    "        d_output_weights = np.dot(self.fc_out.T, d_output)\n",
    "        d_output_bias = np.sum(d_output, axis=0)\n",
    "        \n",
    "        d_fc_out = np.dot(d_output, self.output_weights.T)\n",
    "        d_fc_out[self.fc_out <= 0] = 0\n",
    "        \n",
    "        d_fc_weights = np.dot(self.flattened.T, d_fc_out)\n",
    "        d_fc_bias = np.sum(d_fc_out, axis=0)\n",
    "        \n",
    "        d_pool2_out = np.dot(d_fc_out, self.fc_weights.T)\n",
    "        \n",
    "        d_conv2_out = d_pool2_out.reshape(self.conv2_out.shape)\n",
    "        d_conv2_out[self.conv2_out <= 0] = 0\n",
    "        \n",
    "        d_conv2_filters = np.dot(d_conv2_out, self.pool1_out.T)\n",
    "        d_conv2_bias = np.sum(d_conv2_out, axis=(0, 1, 2))\n",
    "        \n",
    "        d_pool1_out = np.dot(d_conv2_out, self.conv2_filters.T)\n",
    "        \n",
    "        d_conv1_out = d_pool1_out.reshape(self.conv1_out.shape)\n",
    "        d_conv1_out[self.conv1_out <= 0] = 0\n",
    "        \n",
    "        d_conv1_filters = np.dot(d_conv1_out, X.T)\n",
    "        d_conv1_bias = np.sum(d_conv1_out, axis=(0, 1, 2))\n",
    "        \n",
    "        # Обновляем веса\n",
    "        self.conv1_filters -= learning_rate * d_conv1_filters\n",
    "        self.conv1_bias -= learning_rate * d_conv1_bias\n",
    "        self.conv2_filters -= learning_rate * d_conv2_filters\n",
    "        self.conv2_bias -= learning_rate * d_conv2_bias\n",
    "        self.fc_weights -= learning_rate * d_fc_weights\n",
    "        self.fc_bias -= learning_rate * d_fc_bias\n",
    "        self.output_weights -= learning_rate * d_output_weights\n",
    "        self.output_bias -= learning_rate * d_output_bias\n",
    "\n",
    "    def train(self, X_train, y_train, learning_rate=0.001, epochs=10, batch_size=32):\n",
    "        # Убедимся, что X_train имеет правильную форму\n",
    "        if X_train.shape[-1] != 1:\n",
    "            X_train = np.expand_dims(X_train, axis=-1)  # Добавляем канал\n",
    "\n",
    "        num_samples = X_train.shape[0]\n",
    "        \n",
    "        # Преобразуем метки в формат one-hot\n",
    "        y_train = to_categorical(y_train, self.num_classes)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            num_batches = num_samples // batch_size\n",
    "            for batch in range(num_batches):\n",
    "                start_idx = batch * batch_size\n",
    "                end_idx = (batch + 1) * batch_size\n",
    "                X_batch = X_train[start_idx:end_idx]\n",
    "                y_batch = y_train[start_idx:end_idx]\n",
    "                \n",
    "                predictions = self.forward_pass(X_batch)\n",
    "                \n",
    "                loss = cross_entropy_loss(y_batch, predictions)\n",
    "                total_loss += loss\n",
    "                \n",
    "                self.backward_pass(X_batch, y_batch, learning_rate)\n",
    "            \n",
    "            avg_loss = total_loss / num_batches\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация изображений в диапазон [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Преобразование изображений в форму (batch_size, height, width, channels)\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # (60000, 28, 28, 1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)    # (10000, 28, 28, 1)\n",
    "\n",
    "# Преобразование меток в формат one-hot\n",
    "Y_train = to_categorical(Y_train, 10)  # 10 классов\n",
    "Y_test = to_categorical(Y_test, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 189\u001b[0m, in \u001b[0;36mCNN.train\u001b[1;34m(self, X_train, y_train, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[0;32m    186\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_train[start_idx:end_idx]\n\u001b[0;32m    187\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[start_idx:end_idx]\n\u001b[1;32m--> 189\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(y_batch, predictions)\n\u001b[0;32m    192\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[55], line 103\u001b[0m, in \u001b[0;36mCNN.forward_pass\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Свертка первого слоя + активация\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_out \u001b[38;5;241m=\u001b[39m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1_filters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_out \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_out)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Слой пулинга\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 36\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(input, filters, stride, padding)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv2d\u001b[39m(\u001b[38;5;28minput\u001b[39m, filters, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 36\u001b[0m     batch_size, in_height, in_width, in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     37\u001b[0m     num_filters, filter_height, filter_width, _ \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Паддинг\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Инициализация модели\n",
    "model = CNN(input_shape=(28, 28, 1), num_classes=10)\n",
    "\n",
    "# Преобразование данных в 4D тензор\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Добавляем канал, если это одноцветные изображения\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Обучение модели\n",
    "model.train(X_train, Y_train, learning_rate=0.001, epochs=10, batch_size=32)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
