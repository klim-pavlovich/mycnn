{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Добавьте путь к папке, где находятся ваши модули\n",
    "sys.path.append(os.path.abspath(\"C:/Users/klimm/Desktop/lab2/layers\"))\n",
    "\n",
    "\n",
    "# Импортируем нужные модули\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Conv2D import Conv2D\n",
    "from Im2Col import Im2Col\n",
    "# from layers.batchnorm import BatchNorm\n",
    "# from layers.dense import Dense\n",
    "# from layers.maxpool import MaxPool\n",
    "# from layers.dropout import Dropout\n",
    "\n",
    "from utils.load_mnist import load_mnist_data\n",
    "from utils.split_train_validation import split_train_validation\n",
    "from utils.one_hot_encode import one_hot_encode\n",
    "\n",
    "from optimizers import adjust_learning_rate, adam_update\n",
    "from losses import l2_regularization, softmax_loss\n",
    "from activations import leaky_relu, softmax\n",
    "from metrics import compute_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем MNIST и разделяем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read magic number: 2051\n",
      "Images: num_images=60000, rows=28, cols=28\n",
      "Loaded 47040000 image pixels.\n",
      "Read magic number: 2049\n",
      "Read magic number: 2051\n",
      "Images: num_images=10000, rows=28, cols=28\n",
      "Loaded 7840000 image pixels.\n",
      "Read magic number: 2049\n",
      "Исходные данные:\n",
      "X_train: (60000, 28, 28), Y_train: (60000,)\n",
      "X_test: (10000, 28, 28), Y_test: (10000,)\n",
      "После разделения:\n",
      "X_train: (42000, 28, 28), Y_train: (42000,)\n",
      "X_test: (18000, 28, 28), Y_test: (18000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Загружаем MNIST данные\n",
    "X_train, Y_train, X_test, Y_test = load_mnist_data()\n",
    "\n",
    "# Проверяем размерности исходных данных\n",
    "print(f\"Исходные данные:\\nX_train: {X_train.shape}, Y_train: {Y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, Y_test: {Y_test.shape}\")\n",
    "\n",
    "# Разделяем обучающую выборку на 70% для обучения и 30% для валидации\n",
    "X_train, X_test, Y_train, Y_test = split_train_validation(X_train, Y_train)\n",
    "\n",
    "# Проверяем размеры новых выборок\n",
    "print(f\"После разделения:\\nX_train: {X_train.shape}, Y_train: {Y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, Y_test: {Y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем и добавляем метки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем ось каналов\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# Нормализуем данные об изображениях в диапазон [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Кодируем метки\n",
    "Y_train = one_hot_encode(Y_train)\n",
    "Y_test = one_hot_encode(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1) (42000, 10) (18000, 28, 28, 1) (18000, 10)\n",
      "0.0 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Проверяем размерности и значения после нормализации\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "print(np.min(X_train), np.max(X_train))  # Ожидается: 0.0 1.0\n",
    "# Проверяем one-hot encoding\n",
    "print(Y_train[0], Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im2col(input_images, kernel_size, stride=1, padding=0):\n",
    "#     \"\"\"\n",
    "#     Преобразует батч изображений в формат столбцов для ускоренной свертки.\n",
    "#     :param input_images: Входные изображения (batch_size, height, width, channels).\n",
    "#     :param kernel_size: Размер фильтра (F_h, F_w).\n",
    "#     :param stride: Шаг свёртки.\n",
    "#     :param padding: Паддинг.\n",
    "#     :return: Развёрнутая матрица.\n",
    "#     \"\"\"\n",
    "#     batch_size, height, width, channels = input_images.shape\n",
    "\n",
    "#     # Размеры фильтра\n",
    "#     if isinstance(kernel_size, int):\n",
    "#         kernel_height = kernel_width = kernel_size\n",
    "#     else:\n",
    "#         kernel_height, kernel_width = kernel_size\n",
    "\n",
    "#     # Применяем паддинг, если он есть\n",
    "#     if padding > 0:\n",
    "#         input_images = np.pad(input_images, [(0, 0), (padding, padding), (padding, padding), (0, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "#     # Размеры выходного изображения для каждого изображения\n",
    "#     out_h = (height + 2 * padding - kernel_height) // stride + 1\n",
    "#     out_w = (width + 2 * padding - kernel_width) // stride + 1\n",
    "\n",
    "#     # Используем as_strided для получения всех \"окон\" (patches)\n",
    "#     shape = (batch_size, out_h, out_w, kernel_height, kernel_width, channels)\n",
    "#     strides = (input_images.strides[0], stride * input_images.strides[1], stride * input_images.strides[2],\n",
    "#                input_images.strides[1], input_images.strides[2], input_images.strides[3])\n",
    "\n",
    "#     # Используем as_strided для создания 6D массива: (batch_size, out_h, out_w, kernel_height, kernel_width, channels)\n",
    "#     patches = np.lib.stride_tricks.as_strided(input_images, shape=shape, strides=strides)\n",
    "\n",
    "#     # Преобразуем 6D массив в 2D, где каждая колонка это развернутый патч (kernel_height * kernel_width * channels)\n",
    "#     im2col_matrix = patches.reshape(batch_size, -1, out_h * out_w)\n",
    "\n",
    "#     # Транспонируем результат, чтобы получить нужный формат\n",
    "#     im2col_matrix = im2col_matrix.transpose(0, 2, 1).reshape(batch_size * out_h * out_w, -1)\n",
    "\n",
    "#     return im2col_matrix\n",
    "\n",
    "\n",
    "# def conv2d_im2col(input_images, filters, stride=1, padding=0, bias=None):\n",
    "#     \"\"\"\n",
    "#     Реализация свёртки для батча изображений с использованием im2col и матричного умножения.\n",
    "#     :param input_images: Входные изображения (N, H, W, C).\n",
    "#     :param filters: Фильтры (K, F_h, F_w, C), где K - количество фильтров.\n",
    "#     :param stride: Шаг свёртки.\n",
    "#     :param padding: Паддинг.\n",
    "#     :param bias: Смещение для каждого фильтра (K).\n",
    "#     :return: Результат свертки (N, out_h, out_w, K).\n",
    "#     \"\"\"\n",
    "#     N, H, W, C = input_images.shape  # N - количество изображений, H - высота, W - ширина, C - количество каналов\n",
    "#     K, F_h, F_w, C_f = filters.shape  # K - количество фильтров, F_h - высота фильтра, F_w - ширина фильтра, C_f - количество каналов в фильтре (должно быть равно C)\n",
    "\n",
    "#     # Проверка: количество каналов фильтра должно совпадать с количеством каналов изображения\n",
    "#     if C != C_f:\n",
    "#         raise ValueError(\"Количество каналов в изображении и фильтре должно совпадать\")\n",
    "\n",
    "#     # Размеры выходного изображения для каждого изображения\n",
    "#     out_h = (H + 2 * padding - F_h) // stride + 1\n",
    "#     out_w = (W + 2 * padding - F_w) // stride + 1\n",
    "\n",
    "#     # Разворачиваем входные данные с помощью im2col\n",
    "#     im2col_matrix = im2col(input_images, (F_h, F_w), stride, padding)\n",
    "\n",
    "#     # Разворачиваем фильтры в одномерные векторы\n",
    "#     filters_col = filters.reshape(K, -1)  # Размерность (K, F_h * F_w * C)\n",
    "\n",
    "#     # Матричное умножение: фильтры * im2col_matrix\n",
    "#     # im2col_matrix теперь имеет форму (N * out_h * out_w, F_h * F_w * C)\n",
    "#     # filters_col имеет форму (K, F_h * F_w * C)\n",
    "#     # Мы выполняем батч матричного умножения, и результат будет (N * out_h * out_w, K)\n",
    "#     out_col = np.matmul(im2col_matrix, filters_col.T)  # Размерность (batch_size * out_h * out_w, K)\n",
    "\n",
    "#     # Восстанавливаем размерность результата\n",
    "#     out = out_col.reshape(N, out_h, out_w, K)\n",
    "\n",
    "#     if bias is not None:\n",
    "#         out += bias.reshape(1, 1, 1, K)\n",
    "\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, kernel_size, num_filters, num_classes, input_channels=1, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-6, dropout_rate = 0.4):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_filters = num_filters\n",
    "        self.num_classes = num_classes\n",
    "        self.input_channels = input_channels\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.dropout_rate = dropout_rate # Коэффициент dropout\n",
    "        self.gamma = np.ones(self.num_filters)\n",
    "        self.beta = np.zeros(self.num_filters)\n",
    "        self.m_gamma = np.zeros_like(self.gamma)\n",
    "        self.v_gamma = np.zeros_like(self.gamma)\n",
    "        self.m_beta = np.zeros_like(self.beta)\n",
    "        self.v_beta = np.zeros_like(self.beta)\n",
    "\n",
    "        F_h, F_w = kernel_size\n",
    "\n",
    "        # Инициализация для сверточных фильтров с использованием He-инициализации\n",
    "        self.filters = np.random.randn(num_filters, F_h, F_w, input_channels) * np.sqrt(2. / (F_h * F_w * input_channels))\n",
    "\n",
    "        self.bias = np.zeros((num_filters,))\n",
    "\n",
    "        self.fc_input_size = (28 - F_h + 1) * (28 - F_w + 1) * num_filters\n",
    "        # Инициализация для fully connected слоев\n",
    "        self.W_fc = np.random.randn(self.fc_input_size, num_classes) * np.sqrt(2. / self.fc_input_size)\n",
    "\n",
    "        self.b_fc = np.zeros((num_classes,))\n",
    "\n",
    "        self.m_filters = np.zeros_like(self.filters)\n",
    "        self.v_filters = np.zeros_like(self.filters)\n",
    "        self.m_bias = np.zeros_like(self.bias)\n",
    "        self.v_bias = np.zeros_like(self.bias)\n",
    "\n",
    "        self.m_W_fc = np.zeros_like(self.W_fc)\n",
    "        self.v_W_fc = np.zeros_like(self.W_fc)\n",
    "        self.m_b_fc = np.zeros_like(self.b_fc)\n",
    "        self.v_b_fc = np.zeros_like(self.b_fc)\n",
    "\n",
    "        self.t = 0\n",
    "\n",
    "    def forward(self, X, training=True):\n",
    "        conv_out = Conv2D(X, filters=self.filters, stride=1, padding=0, bias=self.bias)\n",
    "        conv_out_norm, cache = self.batch_norm_forward(conv_out)\n",
    "\n",
    "        pooled_out, max_pool_cache = max_pool(conv_out_norm)\n",
    "        cache['max_pool'] = max_pool_cache\n",
    "\n",
    "        N, H, W, C = pooled_out.shape\n",
    "        self.fc_input = conv_out_norm.reshape(N, H * W * C)\n",
    "\n",
    "        fc_out = self.fully_connected(self.fc_input, self.W_fc, self.b_fc)\n",
    "        fc_out_leaky_relu = self.leaky_relu(fc_out)\n",
    "\n",
    "        if training:\n",
    "            fc_out_leaky_relu = self.dropout_forward(fc_out_leaky_relu)\n",
    "\n",
    "        y_pred = self.softmax(fc_out_leaky_relu)\n",
    "\n",
    "        return y_pred, cache\n",
    "\n",
    "    \n",
    "    def backpropagate(self, X, y_true, dout, cache):\n",
    "        grad_filters = np.zeros_like(self.filters)  # Градиент для фильтров\n",
    "        grad_bias = np.zeros_like(self.bias)  # Градиент для биасов\n",
    "\n",
    "        N, H, W, C = X.shape\n",
    "\n",
    "        # Обратное распространение для max-pooling\n",
    "        if 'max_pool' in cache:\n",
    "            grad_pool = max_pooling_backward(dout, cache['max_pool'], pool_size=2, stride=2, padding=0)\n",
    "            dout = grad_pool  # Обновляем dout для следующего слоя\n",
    "\n",
    "        # Для полносвязанного слоя\n",
    "        if dout.ndim == 2:\n",
    "            grad_W_fc = np.dot(self.fc_input.T, dout)  # Градиенты для весов полносвязанного слоя\n",
    "            grad_b_fc = np.sum(dout, axis=0)  # Градиенты к биасам полносвязанного слоя\n",
    "\n",
    "            return grad_filters, grad_W_fc, grad_b_fc, None, None\n",
    "\n",
    "        # Для свёрточного слоя\n",
    "        elif dout.ndim == 4:\n",
    "            dout_reshaped = dout.reshape(N, H, W, C)\n",
    "\n",
    "            # Обратное распространение через BatchNorm\n",
    "            dx, grad_gamma, grad_beta = self.batch_norm_backward(dout_reshaped, cache['batch_norm'])\n",
    "\n",
    "            # Обратное распространение через сверточный слой\n",
    "            grad_filters = np.sum(X * dx, axis=(0, 1), keepdims=True)  # Градиенты по фильтрам свертки\n",
    "\n",
    "            # Возвращаем градиенты для свертки и BatchNorm\n",
    "            return grad_filters, None, None, grad_gamma, grad_beta\n",
    "\n",
    "        else:\n",
    "            # Если количество измерений в dout не соответствует ожиданиям\n",
    "            raise ValueError(f\"Unexpected number of dimensions for dout: {dout.ndim}\")\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=10, batch_size=64):\n",
    "        \"\"\"Обучение сети с использованием оптимизатора Adam.\"\"\"\n",
    "        num_samples = X_train.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for start in range(0, num_samples, batch_size):\n",
    "                # Получаем текущий батч\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                X_batch = X_train[start:end]\n",
    "                y_batch = y_train[start:end]\n",
    "\n",
    "                # Прямой проход\n",
    "                y_pred, cache = self.forward(X_batch)\n",
    "\n",
    "                # Функция потерь и точность\n",
    "                loss = self.softmax_loss(y_batch, y_pred)\n",
    "                epoch_loss += loss\n",
    "                acc = self.compute_accuracy(y_batch, y_pred)\n",
    "                epoch_acc += acc\n",
    "\n",
    "                # Обратное распространение\n",
    "                dout = y_pred - y_batch\n",
    "                grad_filters, grad_W_fc, grad_b_fc, grad_gamma, grad_beta = self.backpropagate(X_batch, y_batch, dout, cache)\n",
    "\n",
    "                # Обновление параметров с использованием Adam\n",
    "                self.adam_update(grad_W_fc, grad_b_fc, grad_filters, grad_gamma, grad_beta)\n",
    "\n",
    "            # Adjust learning rate every 10 epochs\n",
    "            self.adjust_learning_rate(epoch)\n",
    "\n",
    "            # Вывод потерь и точности каждую эпоху\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / (num_samples // batch_size):.4f}, Accuracy: {epoch_acc / (num_samples // batch_size):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m cnn \u001b[38;5;241m=\u001b[39m CNN(kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), num_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 231\u001b[0m, in \u001b[0;36mCNN.train\u001b[1;34m(self, X_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[0;32m    228\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[start:end]\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_pred, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Функция потерь и точность\u001b[39;00m\n\u001b[0;32m    234\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax_loss(y_batch, y_pred)\n",
      "Cell \u001b[1;32mIn[16], line 77\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, X, training)\u001b[0m\n\u001b[0;32m     74\u001b[0m conv_out \u001b[38;5;241m=\u001b[39m conv2d_im2col(X, filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m     75\u001b[0m conv_out_norm, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm_forward(conv_out)\n\u001b[1;32m---> 77\u001b[0m pooled_out, max_pool_cache \u001b[38;5;241m=\u001b[39m max_pooling(conv_out_norm)\n\u001b[0;32m     78\u001b[0m cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_pool\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m max_pool_cache\n\u001b[0;32m     80\u001b[0m N, H, W, C \u001b[38;5;241m=\u001b[39m pooled_out\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Пример инициализации и обучения\n",
    "cnn = CNN(kernel_size=(5, 5), num_filters=32, num_classes=10, learning_rate=0.0001)\n",
    "# Обучение модели\n",
    "cnn.train(X_train, Y_train, epochs=1000, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 8.0281, Accuracy: 0.4645\n",
      "Epoch 2/10, Loss: 8.7033, Accuracy: 0.4658\n",
      "Epoch 3/10, Loss: 8.7301, Accuracy: 0.4711\n",
      "Epoch 4/10, Loss: 8.7747, Accuracy: 0.4720\n",
      "Epoch 5/10, Loss: 8.7773, Accuracy: 0.4761\n",
      "Epoch 6/10, Loss: 8.9009, Accuracy: 0.4726\n",
      "Epoch 7/10, Loss: 9.1026, Accuracy: 0.4718\n",
      "Epoch 8/10, Loss: 9.1885, Accuracy: 0.4722\n",
      "Epoch 9/10, Loss: 9.3865, Accuracy: 0.4711\n",
      "Epoch 10/10, Loss: 9.4948, Accuracy: 0.4762\n"
     ]
    }
   ],
   "source": [
    "# Пример инициализации и обучения\n",
    "cnn = CNN(kernel_size=(3, 3), num_filters=32, num_classes=10, learning_rate=0.0001)\n",
    "# Обучение модели\n",
    "cnn.train(X_train, Y_train, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    def dropout_forward(self, x, training=True):\n",
    "#         if not training:\n",
    "#             return x  # Возвращаем без изменений на этапе тестирования\n",
    "#         # Случайным образом выключаем нейроны\n",
    "#         mask = (np.random.rand(*x.shape) < self.dropout_rate) / self.dropout_rate # Масштабируем веса на тестировании\n",
    "#         return x* mask\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# def fully_connected(self, input_data, weights, bias):\n",
    "#     return np.dot(input_data, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 11.3275, Accuracy: 0.1022\n",
      "Epoch 2/10, Loss: 9.1683, Accuracy: 0.1202\n",
      "Epoch 3/10, Loss: 8.8478, Accuracy: 0.1246\n",
      "Epoch 4/10, Loss: 9.0712, Accuracy: 0.1258\n",
      "Epoch 5/10, Loss: 9.6075, Accuracy: 0.1270\n",
      "Epoch 6/10, Loss: 10.4819, Accuracy: 0.1215\n",
      "Epoch 7/10, Loss: 10.5304, Accuracy: 0.1231\n",
      "Epoch 8/10, Loss: 10.5588, Accuracy: 0.1276\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m cnn \u001b[38;5;241m=\u001b[39m CNN(kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), num_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Загрузите MNIST или другие данные\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 237\u001b[0m, in \u001b[0;36mCNN.train\u001b[1;34m(self, X_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[0;32m    234\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[start:end]\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m y_pred, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# Compute loss with L2 defualt\u001b[39;00m\n\u001b[0;32m    240\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax_loss(y_batch, y_pred)\n",
      "Cell \u001b[1;32mIn[20], line 89\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, X, training)\u001b[0m\n\u001b[0;32m     85\u001b[0m out_w \u001b[38;5;241m=\u001b[39m (W \u001b[38;5;241m-\u001b[39m F_w \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_input \u001b[38;5;241m=\u001b[39m conv_out_norm\u001b[38;5;241m.\u001b[39mreshape(N, out_h \u001b[38;5;241m*\u001b[39m out_w \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_filters)\n\u001b[1;32m---> 89\u001b[0m fc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfully_connected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_fc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m fc_out_leaky_relu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(fc_out)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n",
      "Cell \u001b[1;32mIn[20], line 169\u001b[0m, in \u001b[0;36mCNN.fully_connected\u001b[1;34m(self, input_data, weights, bias)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfully_connected\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data, weights, bias):\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bias\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Пример инициализации и обучения\n",
    "cnn = CNN(kernel_size=(3, 3), num_filters=32, num_classes=10, learning_rate=0.001)\n",
    "# Обучение модели\n",
    "cnn.train(X_train, Y_train, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @jit(nopython=True, parallel=True)\n",
    "# def im2col_optimized_numba(input_images, kernel_size, stride=1, padding=0):\n",
    "#     batch_size, height, width, channels = input_images.shape\n",
    "#     if isinstance(kernel_size, int):\n",
    "#         kernel_height = kernel_width = kernel_size\n",
    "#     else:\n",
    "#         kernel_height, kernel_width = kernel_size\n",
    "\n",
    "#     if padding > 0:\n",
    "#         input_images = np.pad(input_images, [(0, 0), (padding, padding), (padding, padding), (0, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "#     out_h = (height + 2 * padding - kernel_height) // stride + 1\n",
    "#     out_w = (width + 2 * padding - kernel_width) // stride + 1\n",
    "\n",
    "#     unfold = np.zeros((batch_size, kernel_height * kernel_width * channels, out_h * out_w))\n",
    "\n",
    "#     for n in range(batch_size):\n",
    "#         for i in range(0, out_h * stride, stride):\n",
    "#             for j in range(0, out_w * stride, stride):\n",
    "#                 patch = input_images[n, i:i + kernel_height, j:j + kernel_width, :]\n",
    "#                 unfold[n, :, (i // stride) * out_w + (j // stride)] = patch.flatten()\n",
    "\n",
    "#     return unfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @jit(nopython=True, parallel=True)\n",
    "# def im2col_optimized_numba(input_images, kernel_size, stride=1, padding=0):\n",
    "#     batch_size, height, width, channels = input_images.shape\n",
    "#     if isinstance(kernel_size, int):\n",
    "#         kernel_height = kernel_width = kernel_size\n",
    "#     else:\n",
    "#         kernel_height, kernel_width = kernel_size\n",
    "\n",
    "#     if padding > 0:\n",
    "#         input_images = np.pad(input_images, [(0, 0), (padding, padding), (padding, padding), (0, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "#     out_h = (height + 2 * padding - kernel_height) // stride + 1\n",
    "#     out_w = (width + 2 * padding - kernel_width) // stride + 1\n",
    "\n",
    "#     unfold = np.zeros((batch_size, kernel_height * kernel_width * channels, out_h * out_w))\n",
    "\n",
    "#     for n in range(batch_size):\n",
    "#         for i in range(0, out_h * stride, stride):\n",
    "#             for j in range(0, out_w * stride, stride):\n",
    "#                 patch = input_images[n, i:i + kernel_height, j:j + kernel_width, :]\n",
    "#                 unfold[n, :, (i // stride) * out_w + (j // stride)] = patch.flatten()\n",
    "\n",
    "#     return unfold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN:\n",
    "#     def __init__(self, kernel_size, num_filters, num_classes, input_channels=1, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-6, dropout_rate = 0.4):\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.num_filters = num_filters\n",
    "#         self.num_classes = num_classes\n",
    "#         self.input_channels = input_channels\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.beta1 = beta1\n",
    "#         self.beta2 = beta2\n",
    "#         self.epsilon = epsilon\n",
    "#         self.dropout_rate = dropout_rate # Коэффициент dropout\n",
    "#         self.gamma = np.ones(self.num_filters)\n",
    "#         self.beta = np.zeros(self.num_filters)\n",
    "#         self.m_gamma = np.zeros_like(self.gamma)\n",
    "#         self.v_gamma = np.zeros_like(self.gamma)\n",
    "#         self.m_beta = np.zeros_like(self.beta)\n",
    "#         self.v_beta = np.zeros_like(self.beta)\n",
    "\n",
    "#         F_h, F_w = kernel_size\n",
    "\n",
    "#         # Инициализация для сверточных фильтров с использованием He-инициализации\n",
    "#         self.filters = np.random.randn(num_filters, F_h, F_w, input_channels) * np.sqrt(2. / (F_h * F_w * input_channels))\n",
    "\n",
    "#         self.bias = np.zeros((num_filters,))\n",
    "\n",
    "#         self.fc_input_size = (28 - F_h + 1) * (28 - F_w + 1) * num_filters\n",
    "#         # Инициализация для fully connected слоев\n",
    "#         self.W_fc = np.random.randn(self.fc_input_size, num_classes) * np.sqrt(2. / self.fc_input_size)\n",
    "\n",
    "#         self.b_fc = np.zeros((num_classes,))\n",
    "\n",
    "#         self.m_filters = np.zeros_like(self.filters)\n",
    "#         self.v_filters = np.zeros_like(self.filters)\n",
    "#         self.m_bias = np.zeros_like(self.bias)\n",
    "#         self.v_bias = np.zeros_like(self.bias)\n",
    "\n",
    "#         self.m_W_fc = np.zeros_like(self.W_fc)\n",
    "#         self.v_W_fc = np.zeros_like(self.W_fc)\n",
    "#         self.m_b_fc = np.zeros_like(self.b_fc)\n",
    "#         self.v_b_fc = np.zeros_like(self.b_fc)\n",
    "\n",
    "#         self.t = 0\n",
    "\n",
    "#     def forward(self, X, training=True):\n",
    "#         conv_out = Conv2D(X, filters=self.filters, stride=1, padding=0, bias=self.bias)\n",
    "#         conv_out_norm, cache = self.batch_norm_forward(conv_out)\n",
    "\n",
    "#         pooled_out, max_pool_cache = max_pool(conv_out_norm)\n",
    "#         cache['max_pool'] = max_pool_cache\n",
    "\n",
    "#         N, H, W, C = pooled_out.shape\n",
    "#         self.fc_input = conv_out_norm.reshape(N, H * W * C)\n",
    "\n",
    "#         fc_out = self.fully_connected(self.fc_input, self.W_fc, self.b_fc)\n",
    "#         fc_out_leaky_relu = self.leaky_relu(fc_out)\n",
    "\n",
    "#         if training:\n",
    "#             fc_out_leaky_relu = self.dropout_forward(fc_out_leaky_relu)\n",
    "\n",
    "#         y_pred = self.softmax(fc_out_leaky_relu)\n",
    "\n",
    "#         return y_pred, cache\n",
    "\n",
    "    \n",
    "#     def backpropagate(self, X, y_true, dout, cache):\n",
    "#         grad_filters = np.zeros_like(self.filters)  # Градиент для фильтров\n",
    "#         grad_bias = np.zeros_like(self.bias)  # Градиент для биасов\n",
    "\n",
    "#         N, H, W, C = X.shape\n",
    "\n",
    "#         # Обратное распространение для max-pooling\n",
    "#         if 'max_pool' in cache:\n",
    "#             grad_pool = max_pooling_backward(dout, cache['max_pool'], pool_size=2, stride=2, padding=0)\n",
    "#             dout = grad_pool  # Обновляем dout для следующего слоя\n",
    "\n",
    "#         # Для полносвязанного слоя\n",
    "#         if dout.ndim == 2:\n",
    "#             grad_W_fc = np.dot(self.fc_input.T, dout)  # Градиенты для весов полносвязанного слоя\n",
    "#             grad_b_fc = np.sum(dout, axis=0)  # Градиенты к биасам полносвязанного слоя\n",
    "\n",
    "#             return grad_filters, grad_W_fc, grad_b_fc, None, None\n",
    "\n",
    "#         # Для свёрточного слоя\n",
    "#         elif dout.ndim == 4:\n",
    "#             dout_reshaped = dout.reshape(N, H, W, C)\n",
    "\n",
    "#             # Обратное распространение через BatchNorm\n",
    "#             dx, grad_gamma, grad_beta = self.batch_norm_backward(dout_reshaped, cache['batch_norm'])\n",
    "\n",
    "#             # Обратное распространение через сверточный слой\n",
    "#             grad_filters = np.sum(X * dx, axis=(0, 1), keepdims=True)  # Градиенты по фильтрам свертки\n",
    "\n",
    "#             # Возвращаем градиенты для свертки и BatchNorm\n",
    "#             return grad_filters, None, None, grad_gamma, grad_beta\n",
    "\n",
    "#         else:\n",
    "#             # Если количество измерений в dout не соответствует ожиданиям\n",
    "#             raise ValueError(f\"Unexpected number of dimensions for dout: {dout.ndim}\")\n",
    "\n",
    "\n",
    "\n",
    "#     def train(self, X_train, y_train, epochs=10, batch_size=64):\n",
    "#         \"\"\"Обучение сети с использованием оптимизатора Adam.\"\"\"\n",
    "#         num_samples = X_train.shape[0]\n",
    "#         for epoch in range(epochs):\n",
    "#             epoch_loss = 0\n",
    "#             epoch_acc = 0\n",
    "#             for start in range(0, num_samples, batch_size):\n",
    "#                 # Получаем текущий батч\n",
    "#                 end = min(start + batch_size, num_samples)\n",
    "#                 X_batch = X_train[start:end]\n",
    "#                 y_batch = y_train[start:end]\n",
    "\n",
    "#                 # Прямой проход\n",
    "#                 y_pred, cache = self.forward(X_batch)\n",
    "\n",
    "#                 # Функция потерь и точность\n",
    "#                 loss = self.softmax_loss(y_batch, y_pred)\n",
    "#                 epoch_loss += loss\n",
    "#                 acc = self.compute_accuracy(y_batch, y_pred)\n",
    "#                 epoch_acc += acc\n",
    "\n",
    "#                 # Обратное распространение\n",
    "#                 dout = y_pred - y_batch\n",
    "#                 grad_filters, grad_W_fc, grad_b_fc, grad_gamma, grad_beta = self.backpropagate(X_batch, y_batch, dout, cache)\n",
    "\n",
    "#                 # Обновление параметров с использованием Adam\n",
    "#                 self.adam_update(grad_W_fc, grad_b_fc, grad_filters, grad_gamma, grad_beta)\n",
    "\n",
    "#             # Adjust learning rate every 10 epochs\n",
    "#             self.adjust_learning_rate(epoch)\n",
    "\n",
    "#             # Вывод потерь и точности каждую эпоху\n",
    "#             print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / (num_samples // batch_size):.4f}, Accuracy: {epoch_acc / (num_samples // batch_size):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
